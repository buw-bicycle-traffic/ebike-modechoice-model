{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa26e54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.min_rows', 10)\n",
    "pd.set_option('display.max_rows', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77405114",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv('D:/B3_Lokal-Datensatzpaket/CSV/MiD2017_Lokal_Wege.csv', sep=';', usecols = ['H_ID_Lok', 'P_ID', 'W_ID', 'W_GEW', 'W_DETAIL', 'hwzweck1', 'wegkm', 'W_VM_B', 'W_VM_C', 'W_VM_H', 'hvm', 'weg_intermod', 'vm_kombi', 'H_CS', 'alter_gr', 'HP_SEX', 'P_BIL', 'oek_status', 'hhgr_gr2', 'vpedrad', 'P_VAUTO', 'P_STKFZ', 'P_FKARTE', 'saison', 'PRAEZISION', 'GITTER_1km', 'GITTER_SO_500m', 'GITTER_SO_1km', 'PRAEZISION_SO', 'GITTER_ZO_500m', 'GITTER_ZO_1km', 'PRAEZISION_ZO'])\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80caf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of unique trips, persons, and households before data processing\n",
    "print(\"HH in the dataset: \" + str(d['H_ID_Lok'].nunique()))\n",
    "print(\"Persons in the dataset:\", d[['H_ID_Lok', 'P_ID']].drop_duplicates().shape[0])\n",
    "print('Trips in the dataset: ',len(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf8703a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove trips with length > 100 (also includes missing/unplausible lengths)\n",
    "# loses around 10% of trips\n",
    "d['wegkm'] = d['wegkm'].str.replace(',','.')\n",
    "d['wegkm'] = d['wegkm'].astype(float)\n",
    "d = d[d.wegkm <= 100]\n",
    "# take ln of trip length\n",
    "d['dist_ln'] = np.log(d['wegkm'])\n",
    "d['dist_ln'] = d['dist_ln'].apply(lambda x: 0 if x < 0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b9d645",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create mode choice variable from \"hvm\" and \"W_VM_B\" to differentiate between bicycle types\n",
    "# 1: foot, 21: c-bike, 22: e-bike, 3: car (passenger), 4: car (driver), 5: pt\n",
    "def create_choice(row):\n",
    "    if row['hvm'] == 2:\n",
    "        if row['W_VM_B'] == 0:\n",
    "            return 21\n",
    "        else:\n",
    "            return 22\n",
    "    else:\n",
    "        return row['hvm']\n",
    "d['choice'] = d.apply(create_choice, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75432e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calulate mode share before processing to later readjust weights after removing trips with missing data\n",
    "d['W_GEW'] = d['W_GEW'].str.replace(',', '.').astype(float)\n",
    "avweight=d['W_GEW'].sum()/len(d)\n",
    "print(avweight)\n",
    "modeshare_before_processing_weighted = d.groupby('choice')['W_GEW'].sum() / d['W_GEW'].sum()\n",
    "print(modeshare_before_processing_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b71895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove trips that are missing 1km cell for start or destination.\n",
    "d = d[(d['GITTER_SO_1km'].str.contains('1km')) & (d['GITTER_ZO_1km'].str.contains('1km'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26aed0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Throw out other missing values \n",
    "d = d[d.HP_SEX != 9]\n",
    "d = d[d.alter_gr != 99]\n",
    "d = d[d.P_BIL != 9]\n",
    "d = d[d.hwzweck1 != 99]\n",
    "d = d[d.hvm != 9]\n",
    "d = d[d.hvm != 703]\n",
    "d = d[d.vpedrad != 9]\n",
    "d = d[d.vpedrad != 200]\n",
    "d = d[d.P_FKARTE != 99]\n",
    "d = d[d.P_FKARTE != 200]\n",
    "d = d[d.P_VAUTO != 9]\n",
    "d = d[d.P_VAUTO != 200]\n",
    "d = d[d.P_STKFZ != 9]\n",
    "d = d[d.P_STKFZ != 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdea97ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recode P_STKFZ to mean: 1 = access to a car (at least sometimes), 0 = no access\n",
    "dict = {1 : 1, 2 : 1, 3: 0}\n",
    "d=d.replace({\"P_STKFZ\": dict})\n",
    "\n",
    "#recode P_FKARTE to ticket to mean 1 = 3,4, or 5; 0 = no fixed-rate ticket\n",
    "dict = {1 : 0, 2 : 0, 3: 1, 4: 1, 5: 1, 6: 0, 7: 0}\n",
    "d=d.replace({\"P_FKARTE\": dict})\n",
    "d=d.rename(columns={\"P_FKARTE\": \"ticket\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79ff0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#throw out trips where no car available but mode is card or carp\n",
    "mask = (d.P_STKFZ == 0) & (d.hvm.isin([3, 4]))\n",
    "d = d[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3286ef88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create binary bicycle types availabilities\n",
    "d['cbikeav'] = d['vpedrad'].apply(lambda x: 1 if x in [1, 3] else 0)\n",
    "d['ebikeav'] = d['vpedrad'].apply(lambda x: 1 if x in [2, 3] else 0)\n",
    "#throw out trips where cbikeav=0 but mode is cbike\n",
    "d = d[~((d['cbikeav'] == 0) & (d['choice'].isin([21])))]\n",
    "#throw out trips where ebikeav=0 but mode is ebike\n",
    "d = d[~((d['ebikeav'] == 0) & (d['choice'].isin([22])))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a7b5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raumtyp, slope, pt departures and cycling infra coverage for origin and destination\n",
    "\n",
    "# read data for all 1km cells in Germany\n",
    "cells = pd.read_csv('C:/Users/arning.FUL/Desktop/11_Mode_Choice/1km_Raumtyp_Slope_ptqual_infra.csv', usecols=['cellname', 'Raumtyp', 'slope', 'departures', 'cycling_coverage'])\n",
    "\n",
    "# write Raumtyp to trip data\n",
    "d['Raumtyp_SO'] = d['GITTER_SO_1km'].map(cells.set_index('cellname')['Raumtyp'])\n",
    "d['Raumtyp_ZO'] = d['GITTER_ZO_1km'].map(cells.set_index('cellname')['Raumtyp'])\n",
    "\n",
    "# write Slope to trip data\n",
    "d['slope_SO'] = d['GITTER_SO_1km'].map(cells.set_index('cellname')['slope'])\n",
    "d['slope_ZO'] = d['GITTER_ZO_1km'].map(cells.set_index('cellname')['slope'])\n",
    "\n",
    "# write number of stops (2km radius around cell center) to trip data\n",
    "d['departures_SO'] = d['GITTER_SO_1km'].map(cells.set_index('cellname')['departures'])\n",
    "d['departures_ZO'] = d['GITTER_ZO_1km'].map(cells.set_index('cellname')['departures'])\n",
    "\n",
    "# write cycling infrastructure coverage to trip data\n",
    "d['cyclinfra_SO'] = d['GITTER_SO_1km'].map(cells.set_index('cellname')['cycling_coverage'])\n",
    "d['cyclinfra_ZO'] = d['GITTER_ZO_1km'].map(cells.set_index('cellname')['cycling_coverage'])\n",
    "\n",
    "# throw out trips where origin or destination do not have a raumtyp (only 300 trips)\n",
    "a = [11.0, 12.0, 21.0, 22.0]\n",
    "d = d[d['Raumtyp_SO'].isin(a)]\n",
    "d = d[d['Raumtyp_ZO'].isin(a)]\n",
    "\n",
    "# throw out trips where slope is none (0 trips)\n",
    "d = d.dropna(subset=['slope_SO'])\n",
    "d = d.dropna(subset=['slope_ZO'])\n",
    "\n",
    "# throw out trips where slope is none (only 95 trips)\n",
    "d = d.dropna(subset=['cyclinfra_SO'])\n",
    "d = d.dropna(subset=['cyclinfra_ZO'])\n",
    "\n",
    "# for departures, set Nan to 0\n",
    "d['departures_SO'] = d['departures_SO'].fillna(0)\n",
    "d['departures_ZO'] = d['departures_ZO'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bb4a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# postprocessing pt departures\n",
    "# replace 0 to be able to apply log\n",
    "d['departures_SO'] = d['departures_SO'].replace({0:1})\n",
    "d['departures_ZO'] = d['departures_ZO'].replace({0:1})\n",
    "\n",
    "# apply natural logarithm\n",
    "d['departures_SO_ln'] = np.log(d['departures_SO'])\n",
    "d['departures_ZO_ln'] = np.log(d['departures_ZO'])\n",
    "\n",
    "# replace negative values with 0\n",
    "d.loc[d['departures_SO_ln'] < 0, 'departures_SO_ln'] = 0\n",
    "d.loc[d['departures_ZO_ln'] < 0, 'departures_ZO_ln'] = 0\n",
    "\n",
    "# testing showed same parameter for O and D, therefore take average of variable\n",
    "d['departures_ln'] = (d['departures_SO_ln']+d['departures_ZO_ln'])/2\n",
    "d['departures_ln'] = d['departures_ln'].round(decimals=2)\n",
    "d['departures'] = (d['departures_SO']+d['departures_ZO'])/2 # for plotting\n",
    "d = d.drop('departures_SO_ln', axis=1)\n",
    "d = d.drop('departures_ZO_ln', axis=1)\n",
    "d = d.drop('departures_SO', axis=1)\n",
    "d = d.drop('departures_ZO', axis=1)\n",
    "\n",
    "# postprocessing gradient\n",
    "# compute max slope for O and D\n",
    "def find_maximum_slope(row):\n",
    "    return max(row['slope_SO'], row['slope_ZO'])\n",
    "d['grad'] = d.apply(find_maximum_slope, axis=1)\n",
    "d['grad'] = d['grad'].round(2)\n",
    "d = d.drop('slope_SO', axis=1)\n",
    "d = d.drop('slope_ZO', axis=1)\n",
    "\n",
    "# postprocessing infra\n",
    "# compute average cycling infra between O and D\n",
    "d['cyclinfra'] = (d['cyclinfra_SO']+d['cyclinfra_ZO'])/2\n",
    "d['cyclinfra'] = d['cyclinfra'].round(3)\n",
    "d = d.drop('cyclinfra_SO', axis=1)\n",
    "d = d.drop('cyclinfra_ZO', axis=1)\n",
    "\n",
    "# where spatial typology for origin and destination is different, use the higher (more peripheral) value\n",
    "d['Raumtyp_SO'] = d['Raumtyp_SO'].astype(int)\n",
    "d['Raumtyp_ZO'] = d['Raumtyp_ZO'].astype(int)\n",
    "def find_maximum(row):\n",
    "    return max(row['Raumtyp_SO'], row['Raumtyp_ZO'])\n",
    "d['spattyp'] = d.apply(find_maximum, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1bc9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate new weights to adjust for distortions in mode share after data processing\n",
    "modeshare_after_processing_weighted = d.groupby('choice')['W_GEW'].sum() / d['W_GEW'].sum()\n",
    "print(modeshare_before_processing_weighted)\n",
    "print(modeshare_after_processing_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b766744",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate reweighting per mode to adjust for newly introduced distortion\n",
    "temp = {'mode': [1,3,4,5,21,22], 'reweight':[modeshare_before_processing_weighted[1]/modeshare_after_processing_weighted[1],\n",
    "                                           modeshare_before_processing_weighted[3]/modeshare_after_processing_weighted[3],\n",
    "                                           modeshare_before_processing_weighted[4]/modeshare_after_processing_weighted[4],\n",
    "                                           modeshare_before_processing_weighted[5]/modeshare_after_processing_weighted[5],\n",
    "                                           modeshare_before_processing_weighted[21]/modeshare_after_processing_weighted[21],\n",
    "                                           modeshare_before_processing_weighted[22]/modeshare_after_processing_weighted[22]]}\n",
    "# Create a dictionary mapping values in 'mode' to corresponding 'reweight' values\n",
    "reweighting = pd.DataFrame(data=temp)\n",
    "reweighting = reweighting.set_index('mode')\n",
    "reweight_dict = reweighting['reweight'].to_dict()\n",
    "d['W_GEW_new'] = d['choice'].map(reweight_dict) * d['W_GEW']\n",
    "#readjust new weights to an average of 1\n",
    "d['W_GEW_new'] = d['W_GEW_new']/d[['W_GEW_new']].mean()[0]\n",
    "#reweighting.to_csv('E:/PLUGIN/11_Mode_Choice/mode-reweighting.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f3d0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummify variables\n",
    "\n",
    "# mobility tool availabilities are already coded as three binary dummy variables\n",
    "\n",
    "# trip purpose\n",
    "dummies_purp = pd.get_dummies(d['hwzweck1'], prefix='purp', dtype=int)\n",
    "dummies_purp = dummies_purp.rename(columns=lambda x: x.replace('purp', ''))\n",
    "dummies_purp.columns = ['purp' + str(col) for col in dummies_purp.columns]\n",
    "d = d.join(dummies_purp)\n",
    "\n",
    "# Spatial typology\n",
    "dummies_spattyp = pd.get_dummies(d['spattyp'], prefix='spattyp', dtype=int)\n",
    "dummies_spattyp = dummies_spattyp.rename(columns=lambda x: x.replace('spattyp', ''))\n",
    "dummies_spattyp.columns = ['spattyp' + str(col) for col in dummies_spattyp.columns]\n",
    "d = d.join(dummies_spattyp)\n",
    "\n",
    "# season\n",
    "dummies_season = pd.get_dummies(d['saison'], prefix='season', dtype=int)\n",
    "dummies_season = dummies_season.rename(columns=lambda x: x.replace('season', ''))\n",
    "dummies_season.columns = ['season' + str(col) for col in dummies_season.columns]\n",
    "d = d.join(dummies_season)\n",
    "\n",
    "#create binary dummy variables for age, education, gender, hh economic status, hh size\n",
    "dummies_age = pd.get_dummies(d['alter_gr'], prefix='age', dtype=int)\n",
    "dummies_age = dummies_age.rename(columns=lambda x: x.replace('age', ''))\n",
    "dummies_age.columns = ['age' + str(col) for col in dummies_age.columns]\n",
    "d = d.join(dummies_age)\n",
    "\n",
    "dummies_sex = pd.get_dummies(d['HP_SEX'], prefix='sex', dtype=int)\n",
    "dummies_sex = dummies_sex.rename(columns=lambda x: x.replace('sex', ''))\n",
    "dummies_sex.columns = ['sex' + str(col) for col in dummies_sex.columns]\n",
    "d = d.join(dummies_sex)\n",
    "\n",
    "dummies_edu = pd.get_dummies(d['P_BIL'], prefix='edu', dtype=int)\n",
    "dummies_edu = dummies_edu.rename(columns=lambda x: x.replace('edu', ''))\n",
    "dummies_edu.columns = ['edu' + str(col) for col in dummies_edu.columns]\n",
    "d = d.join(dummies_edu)\n",
    "\n",
    "dummies_eco = pd.get_dummies(d['oek_status'], prefix='eco', dtype=int)\n",
    "dummies_eco = dummies_eco.rename(columns=lambda x: x.replace('eco', ''))\n",
    "dummies_eco.columns = ['eco' + str(col) for col in dummies_eco.columns]\n",
    "d = d.join(dummies_eco)\n",
    "\n",
    "dummies_hhsize = pd.get_dummies(d['hhgr_gr2'], prefix='hhsize', dtype=int)\n",
    "dummies_hhsize = dummies_hhsize.rename(columns=lambda x: x.replace('hhsize', ''))\n",
    "dummies_hhsize.columns = ['hhsize' + str(col) for col in dummies_hhsize.columns]\n",
    "d = d.join(dummies_hhsize)\n",
    "\n",
    "# drop the original categorical variables\n",
    "d = d.drop('HP_SEX', axis=1)\n",
    "#d = d.drop('alter_gr', axis=1) keeping age, we use this later for analysis in model validation\n",
    "d = d.rename(columns={\"alter_gr\": \"age\"})\n",
    "d = d.drop('P_BIL', axis=1)\n",
    "d = d.drop('hhgr_gr2', axis=1)\n",
    "d = d.drop('oek_status', axis=1)\n",
    "#d = d.drop('hwzweck1', axis=1) keeping trip purpose, we use this later for analysis in model validation\n",
    "d = d.rename(columns={\"hwzweck1\": \"purp\"})\n",
    "d = d.drop('saison', axis=1)\n",
    "d = d.drop('Raumtyp_SO', axis=1)\n",
    "d = d.drop('Raumtyp_ZO', axis=1)\n",
    "d = d.drop('spattyp', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dd4135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FULL SAMPLE\n",
    "d.to_csv('F:/Processed Data/ModeChoice_input.csv')\n",
    "\n",
    "# 100k SAMPLE #\n",
    "d.sample(100000).to_csv('F:/Processed Data/ModeChoice_input_100000.csv')\n",
    "\n",
    "# 10k SAMPLE #\n",
    "d.sample(10000).to_csv('F:/Processed Data/ModeChoice_input_10000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d3f125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAMPLES of all trips of households from within/outside a specific city (GITTER_1km is HH location)\n",
    "\n",
    "# create list of 1km cells that are within the municipality. ags-to-cells-bridge can be found in Raumtyp.csv\n",
    "cells_ags = pd.read_csv('E:/PLUGIN/11_Mode_Choice/Raumtyp.csv', usecols = ['cellname','ags'])\n",
    "cells_ags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337d7269",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wuppertal\n",
    "cells_wuppertal = cells_ags[cells_ags['ags'] == 5124000]\n",
    "cells_wuppertal\n",
    "\n",
    "d_inWT = d[d['GITTER_1km'].isin(cells_wuppertal['cellname'].tolist())]\n",
    "indices_inWT = d_inWT.index\n",
    "d_outWT = d[~d.index.isin(indices_inWT)]\n",
    "\n",
    "# Convert to different type of int\n",
    "columns_to_convert = [\n",
    "    \"purp_1\", \"purp_2\", \"purp_3\", \"purp_4\", \"purp_5\", \"purp_6\", \"purp_7\",\n",
    "    \"spattyp_11\", \"spattyp_12\", \"spattyp_21\", \"spattyp_22\", \"season_1\", \"season_2\", \"season_3\", \"season_4\",\n",
    "    \"age_1\", \"age_2\", \"age_3\", \"age_4\", \"age_5\", \"age_6\", \"age_7\", \"age_8\",\n",
    "    \"sex_1\", \"sex_2\", \"edu_1\", \"edu_2\", \"edu_3\", \"edu_4\", \"edu_5\", \"edu_6\",\n",
    "    \"eco_1\", \"eco_2\", \"eco_3\", \"eco_4\", \"eco_5\"\n",
    "]\n",
    "\n",
    "d_outWT[columns_to_convert] = d_outWT[columns_to_convert].astype(int)\n",
    "d_inWT[columns_to_convert] = d_inWT[columns_to_convert].astype(int)\n",
    "\n",
    "# Save samples\n",
    "d_inWT.to_csv('F:/Processed Data/cityvalidation/ModeChoice_sim_inWT.csv')\n",
    "d_outWT.to_csv('F:/Processed Data/cityvalidation/ModeChoice_input_outWT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c69e0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MÃ¼nster\n",
    "cells_wuppertal = cells_ags[cells_ags['ags'] == 5515000]\n",
    "cells_wuppertal\n",
    "\n",
    "d_inMS = d[d['GITTER_1km'].isin(cells_wuppertal['cellname'].tolist())]\n",
    "indices_inMS = d_inMS.index\n",
    "d_outMS = d[~d.index.isin(indices_inMS)]\n",
    "\n",
    "d_inMS[columns_to_convert] = d_inMS[columns_to_convert].astype(int)\n",
    "d_outMS[columns_to_convert] = d_outMS[columns_to_convert].astype(int)\n",
    "\n",
    "# Save samples\n",
    "d_inMS.to_csv('F:/Processed Data/cityvalidation/ModeChoice_sim_inMS.csv')\n",
    "d_outMS.to_csv('F:/Processed Data/cityvalidation/ModeChoice_input_outMS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb3c2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Samples k-fold cross validation (k=5)\n",
    "d_shuffled = d.sample(frac = 1)\n",
    "\n",
    "#simulation samples (one fifth of full sample)\n",
    "np.array_split(d_shuffled, 5)[0].to_csv('F:/Processed Data/kfcv/ModeChoice_sim_k1.csv')\n",
    "np.array_split(d_shuffled, 5)[1].to_csv('F:/Processed Data/kfcv/ModeChoice_sim_k2.csv')\n",
    "np.array_split(d_shuffled, 5)[2].to_csv('F:/Processed Data/kfcv/ModeChoice_sim_k3.csv')\n",
    "np.array_split(d_shuffled, 5)[3].to_csv('F:/Processed Data/kfcv/ModeChoice_sim_k4.csv')\n",
    "np.array_split(d_shuffled, 5)[4].to_csv('F:/Processed Data/kfcv/ModeChoice_sim_k5.csv')\n",
    "\n",
    "#estimation samles (four fifths of full sample)\n",
    "pd.concat([np.array_split(d_shuffled, 5)[1],np.array_split(d_shuffled, 5)[2],np.array_split(d_shuffled, 5)[3],np.array_split(d_shuffled, 5)[4]]).to_csv('F:/Processed Data/kfcv/ModeChoice_input_k2345.csv')\n",
    "pd.concat([np.array_split(d_shuffled, 5)[0],np.array_split(d_shuffled, 5)[2],np.array_split(d_shuffled, 5)[3],np.array_split(d_shuffled, 5)[4]]).to_csv('F:/Processed Data/kfcv/ModeChoice_input_k1345.csv')\n",
    "pd.concat([np.array_split(d_shuffled, 5)[0],np.array_split(d_shuffled, 5)[1],np.array_split(d_shuffled, 5)[3],np.array_split(d_shuffled, 5)[4]]).to_csv('F:/Processed Data/kfcv/ModeChoice_input_k1245.csv')\n",
    "pd.concat([np.array_split(d_shuffled, 5)[0],np.array_split(d_shuffled, 5)[1],np.array_split(d_shuffled, 5)[2],np.array_split(d_shuffled, 5)[4]]).to_csv('F:/Processed Data/kfcv/ModeChoice_input_k1235.csv')\n",
    "pd.concat([np.array_split(d_shuffled, 5)[0],np.array_split(d_shuffled, 5)[1],np.array_split(d_shuffled, 5)[2],np.array_split(d_shuffled, 5)[3]]).to_csv('F:/Processed Data/kfcv/ModeChoice_input_k1234.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c3852d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "### DESCRIPTIVE STATS ###\n",
    "#########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe3e10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorical, unweighted\n",
    "def unique_entry_share(df, columns):\n",
    "    result = {}\n",
    "    for column in columns:\n",
    "        counts = df[column].value_counts(normalize=True)\n",
    "        result[column] = counts\n",
    "    return result\n",
    "\n",
    "selected_columns = ['choice','cbikeav','ebikeav','P_STKFZ','ticket', 'age_1','age_2','age_3','age_4','age_5','age_6','age_7','age_8','sex_1','sex_2','edu_1','edu_2','edu_3','edu_4','edu_5','edu_6','eco_1','eco_2','eco_3','eco_4','eco_5','purp_1','purp_2','purp_3','purp_4','purp_5','purp_6','purp_7','season_1','season_2','season_3','season_4','spattyp_11','spattyp_12','spattyp_21','spattyp_22']\n",
    "unique_entry_shares = unique_entry_share(d, selected_columns)\n",
    "\n",
    "for column, counts in unique_entry_shares.items():\n",
    "    print(\"Unique entry share for column '{}':\".format(column))\n",
    "    print(counts)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac981c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorical, weighted\n",
    "def weighted_unique_entry_share(df, columns, weight_column):\n",
    "    result = {}\n",
    "    for column in columns:\n",
    "        counts = df.groupby(column)[weight_column].sum() / df[weight_column].sum()\n",
    "        result[column] = counts\n",
    "    return result\n",
    "\n",
    "weight_column = 'W_GEW_new'  \n",
    "weighted_unique_entry_shares = weighted_unique_entry_share(d, selected_columns, weight_column)\n",
    "\n",
    "for column, counts in weighted_unique_entry_shares.items():\n",
    "    print(\"Weighted unique entry share for column '{}':\".format(column))\n",
    "    print(counts)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3097b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#continuous, unweighted\n",
    "import matplotlib.pyplot as plt\n",
    "medianprops = {'color': 'black'}\n",
    "\n",
    "print(\"distance\")\n",
    "fig = plt.figure(figsize=(5, 2), dpi=1000)\n",
    "plt.rc('font', family='Arial', size=10)\n",
    "#plt.boxplot(d[\"wegkm\"], vert=False, showfliers=False)\n",
    "bp = plt.boxplot(d[\"wegkm\"], vert=False, showfliers=True, medianprops=medianprops, widths=0.25)\n",
    "plt.yticks([1], ['distance\\n[km]'])\n",
    "plt.savefig(\"dist_boxplot.svg\", format='svg')\n",
    "plt.show()\n",
    "print(\"mean:\"+ str(d['wegkm'].mean()))\n",
    "print(\"weighted mean:\"+ str(np.average(d['wegkm'], weights=d['W_GEW_new'])))\n",
    "\n",
    "print(\"gradient\")\n",
    "fig = plt.figure(figsize=(5, 2), dpi=1000)\n",
    "plt.rc('font', family='Arial', size=10)\n",
    "#plt.boxplot(d[\"slope_max\"], vert=False, showfliers=False)\n",
    "bp = plt.boxplot(d[\"grad\"], vert=False, showfliers=True, medianprops=medianprops, widths=0.25)\n",
    "plt.yticks([1], ['gradient\\n[%]'])\n",
    "plt.savefig(\"grad_boxplot.svg\", format='svg')\n",
    "plt.show()\n",
    "print(\"mean:\"+ str(d['grad'].mean()))\n",
    "print(\"weighted mean:\"+ str(np.average(d['grad'], weights=d['W_GEW_new'])))\n",
    "\n",
    "print(\"bic. infra.\")\n",
    "fig = plt.figure(figsize=(5, 2), dpi=1000)\n",
    "plt.rc('font', family='Arial', size=10)\n",
    "#plt.boxplot(d[\"cyclinfra_SOZO\"], vert=False, showfliers=False)\n",
    "bp = plt.boxplot(d[\"cyclinfra\"], vert=False, showfliers=True, medianprops=medianprops, widths=0.25)\n",
    "plt.savefig(\"infra_boxplot.svg\", format='svg')\n",
    "plt.yticks([1], ['bic. infra.'])\n",
    "plt.savefig(\"infra_boxplot.svg\", format='svg')\n",
    "plt.show()\n",
    "print(\"mean:\"+ str(d['cyclinfra'].mean()))\n",
    "print(\"weighted mean:\"+ str(np.average(d['cyclinfra'], weights=d['W_GEW_new'])))\n",
    "\n",
    "print(\"departures\")\n",
    "fig = plt.figure(figsize=(5, 2), dpi=1000)\n",
    "plt.rc('font', family='Arial', size=10)\n",
    "#plt.boxplot(d[\"depart_ln\"], vert=False, showfliers=False)\n",
    "bp = plt.boxplot(d[\"departures\"], vert=False, showfliers=True, medianprops=medianprops, widths=0.25)\n",
    "plt.yticks([1], ['departures'])\n",
    "plt.savefig(\"depart_boxplot.svg\", format='svg')\n",
    "plt.show()\n",
    "print(\"mean:\"+ str(d['departures'].mean()))\n",
    "print(\"weighted mean:\"+ str(np.average(d['departures'], weights=d['W_GEW_new'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e9ae11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#share of trips undertaken by 60+ for leisure purpose among all e-bike trips\n",
    "len(\n",
    "    d[\n",
    "        (\n",
    "            (d['choice']==22)\n",
    "            &(d['hwzweck1_6']==1)\n",
    "            &((d['alter_gr_6'] == 1) | (d['alter_gr_7'] == 1) | (d['alter_gr_8'] == 1))\n",
    "        )\n",
    "    ]\n",
    ")/len(\n",
    "    d[(d['choice']==22)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2f99d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#share of e-bike trips where the person does not own a c-bike\n",
    "len(\n",
    "    d[(d['choice']==22) & (d['cbikeav']==0)]\n",
    ")/len(\n",
    "    d[d['choice']==22]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb603a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of unique trips, persons, and households after data processing\n",
    "print(\"HH in the dataset: \" + str(d['H_ID_Lok'].nunique()))\n",
    "print(\"Persons in the dataset:\", d[['H_ID_Lok', 'P_ID']].drop_duplicates().shape[0])\n",
    "print('Trips in the dataset: ',len(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3a2821",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation matrix between variables\n",
    "#dummify choice for correlation matrix\n",
    "dummies_choice = pd.get_dummies(d['choice'], prefix='choice')\n",
    "dummies_choice = dummies_choice.rename(columns=lambda x: x.replace('choice', ''))\n",
    "dummies_choice.columns = ['choice' + str(col) for col in dummies_choice.columns]\n",
    "d = d.join(dummies_choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab0f49c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columns_to_correlate = ['choice_1','choice_21','choice_22','choice_3','choice_4','choice_5','P_STKFZ','ticket','grad','cyclinfra','departures_ln','spattyp_11','spattyp_21','spattyp_22','purp_3','age_1','age_2','age_7','edu_1','edu_4','edu_5','eco_3','eco_5']\n",
    "# Calculate the correlation matrix (categorical variables are looked at as continous here! Just supposed to give a first overview!)\n",
    "correlation_matrix = d[columns_to_correlate].corr()\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "custom_labels = ['choice_foot', 'choice_cbike', 'choice_ebike', 'choice_carp', 'choice_card', 'choice_pt', 'MT_car', 'MT_ticket', 'grad', 'infra', 'depart_O', 'depart_D', 'spatyp_11', 'spatyp_21', 'spatyp_22', 'purp_3', 'age_1', 'age_2', 'age_7', 'edu_1', 'edu_4', 'edu_5', 'eco_3', 'eco_5']\n",
    "\n",
    "plt.figure(figsize=(25, 20))\n",
    "ax = sns.heatmap(correlation_matrix, square = True, annot=True, cmap='coolwarm', fmt='.2f', annot_kws={\"size\": 14}, vmin=-1, vmax=1, xticklabels=custom_labels, yticklabels=custom_labels, cbar = False)\n",
    "#cbar_ax = ax.figure.add_axes([0.1, -0.05, 0.8, 0.05])  # Adjust the position and size of the color bar as needed\n",
    "#cbar = ax.figure.colorbar(ax.collections[0], cax=cbar_ax, orientation='horizontal')\n",
    "ax.tick_params(axis='both', which='major', labelsize=14, bottom=False, labelbottom=False, top=True, labeltop=True)  # Adjust the text size as needed\n",
    "plt.xticks(rotation=45)\n",
    "plt.savefig(\"corr_matrix.svg\", format='svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d81850",
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "### MAPS ###\n",
    "############\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a632fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spatyp\n",
    "df = pd.read_csv('../1km_Raumtyp_Slope.csv', usecols = ['cellname','Raumtyp'])\n",
    "\n",
    "df['x'] = '0'\n",
    "df['y'] = '0'\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    df.at[index, 'x'] = int(row['cellname'][9:13])\n",
    "    df.at[index, 'y'] = int(row['cellname'][4:8])\n",
    "\n",
    "df = df[df['Raumtyp'].isin([11.0,12.0,21.0,22.0])]\n",
    "\n",
    "df['Raumtyp'] = df['Raumtyp'].astype(int).astype(str)\n",
    "df = df.drop(['cellname'], axis=1)\n",
    "\n",
    "df['x'] = pd.to_numeric(df['x'])\n",
    "df['y'] = pd.to_numeric(df['y'])\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f27e896",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_data = df.pivot(index='y', columns='x', values='Raumtyp')\n",
    "\n",
    "category_colors = {\n",
    "    11: 'lightcoral',\n",
    "    12: 'pink',\n",
    "    21: 'teal',\n",
    "    22: 'palegreen'\n",
    "}\n",
    "\n",
    "# Create a scatter plot for each category with its assigned color\n",
    "plt.figure(figsize=(20, 22))\n",
    "\n",
    "plt.rc('font', family='Arial', size=38)\n",
    "for category, color in category_colors.items():\n",
    "    subset = df[df['Raumtyp'] == str(category)]\n",
    "    plt.scatter(subset['x'], subset['y'], c=color, marker='s', s=0.6, label=f'{category}')\n",
    "\n",
    "#legend\n",
    "h1 = Line2D([0], [0], marker='s', markersize=np.sqrt(20), color='lightcoral', linestyle='None')\n",
    "h2 = Line2D([0], [0], marker='s', markersize=np.sqrt(20), color='pink', linestyle='None')\n",
    "h3 = Line2D([0], [0], marker='s', markersize=np.sqrt(20), color='teal', linestyle='None')\n",
    "h4 = Line2D([0], [0], marker='s', markersize=np.sqrt(20), color='palegreen', linestyle='None')\n",
    "plt.legend([h1, h2, h3, h4], ['urban metropolitan','urban regiopolitan','rural close to city', 'rural peripheral'], markerscale=5, scatterpoints=1, title=\"spatial typology\")\n",
    "\n",
    "#plt.xlabel('X')\n",
    "#plt.ylabel('Y')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.savefig(\"spatyp_map.jpg\", format='jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b6dde3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#departures\n",
    "df = pd.read_csv('../1km_Raumtyp_Slope_ptqual.csv', usecols = ['cellname','departures'])\n",
    "\n",
    "df['x'] = '0'\n",
    "df['y'] = '0'\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    df.at[index, 'x'] = int(row['cellname'][9:13])\n",
    "    df.at[index, 'y'] = int(row['cellname'][4:8])\n",
    "\n",
    "    \n",
    "df = df.drop(['cellname'], axis=1)\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "df['departures_p'] = np.log(df['departures'])\n",
    "df['departures_p'] = df['departures_p'].apply(lambda x: max(x, 0))\n",
    "\n",
    "df['x'] = pd.to_numeric(df['x'])\n",
    "df['y'] = pd.to_numeric(df['y'])\n",
    "df['departures'] = df['departures'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35961da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = plt.Normalize(vmin=df['departures_p'].min(), vmax=df['departures_p'].max())\n",
    "\n",
    "plt.figure(figsize=(20, 22))\n",
    "\n",
    "plt.rc('font', family='Arial', size=38)\n",
    "\n",
    "scatter = plt.scatter(df['x'], df['y'], c=df['departures_p'], marker='s', s=0.6, cmap='viridis', norm=norm)\n",
    "\n",
    "cbar = plt.colorbar(scatter)\n",
    "cbar.set_label('logarithmized public transport departures')\n",
    "\n",
    "#plt.xlabel('X')\n",
    "#plt.ylabel('Y')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.savefig(\"departures_map.jpg\", format='jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcfbe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradient\n",
    "df = pd.read_csv('../1km_Raumtyp_Slope.csv', usecols = ['cellname','slope'])\n",
    "\n",
    "df['x'] = '0'\n",
    "df['y'] = '0'\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    df.at[index, 'x'] = int(row['cellname'][9:13])\n",
    "    df.at[index, 'y'] = int(row['cellname'][4:8])\n",
    "\n",
    "df = df.drop(['cellname'], axis=1)\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "df['x'] = pd.to_numeric(df['x'])\n",
    "df['y'] = pd.to_numeric(df['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9b2af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = plt.Normalize(vmin=df['slope'].min(), vmax=20)\n",
    "\n",
    "plt.figure(figsize=(20, 22))\n",
    "\n",
    "plt.rc('font', family='Arial', size=38)\n",
    "\n",
    "scatter = plt.scatter(df['x'], df['y'], c=df['slope'], marker='s', s=0.6, cmap='Greys', norm=norm)\n",
    "\n",
    "cbar = plt.colorbar(scatter)\n",
    "cbar.set_label('terrain gradient')\n",
    "\n",
    "#plt.xlabel('X')\n",
    "#plt.ylabel('Y')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.savefig(\"gradient_map.jpg\", format='jpg')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2587cb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#infrastructure\n",
    "df = pd.read_csv('../1km_Raumtyp_Slope_ptqual_infra.csv', usecols = ['cellname','cycling_coverage'])\n",
    "\n",
    "df['x'] = '0'\n",
    "df['y'] = '0'\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    df.at[index, 'x'] = int(row['cellname'][9:13])\n",
    "    df.at[index, 'y'] = int(row['cellname'][4:8])\n",
    "\n",
    "df = df.drop(['cellname'], axis=1)\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "df['x'] = pd.to_numeric(df['x'])\n",
    "df['y'] = pd.to_numeric(df['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76e7613",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = plt.Normalize(vmin=df['cycling_coverage'].min(), vmax=df['cycling_coverage'].max())\n",
    "\n",
    "plt.figure(figsize=(20, 22))\n",
    "\n",
    "plt.rc('font', family='Arial', size=38)\n",
    "\n",
    "scatter = plt.scatter(df['x'], df['y'], c=df['cycling_coverage'], marker='s', s=0.6, cmap='viridis', norm=norm)\n",
    "\n",
    "cbar = plt.colorbar(scatter)\n",
    "cbar.set_label('bicycle infrastructure coverage')\n",
    "\n",
    "#plt.xlabel('X')\n",
    "#plt.ylabel('Y')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.savefig(\"infra_map.jpg\", format='jpg')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
